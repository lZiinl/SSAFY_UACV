{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GunshotClassifier 정의 (이전에 사용한 모델)\n",
    "class GunshotClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GunshotClassifier, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멜 스펙트로그램 변환 함수\n",
    "def preprocess_audio(y, sr=22050, duration=1.0, n_mels=128):\n",
    "    # Pad audio to ensure it's at least as long as the desired duration\n",
    "    if len(y) < sr * duration:\n",
    "        y = np.pad(y, (0, sr * duration - len(y)), mode='constant')\n",
    "    # Take the first 1-second clip\n",
    "    y = y[:sr]\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\anaconda3\\envs\\sound\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SSAFY\\anaconda3\\envs\\sound\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GunshotClassifier:\n\tsize mismatch for model.conv1.weight: copying a param with shape torch.Size([64, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 3, 7, 7]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m  \u001b[38;5;66;03m# 총기 클래스 수\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m GunshotClassifier(num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgunshot_classifier.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 데이터 증강 및 전처리 설정\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\anaconda3\\envs\\sound\\lib\\site-packages\\torch\\nn\\modules\\module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GunshotClassifier:\n\tsize mismatch for model.conv1.weight: copying a param with shape torch.Size([64, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 3, 7, 7])."
     ]
    }
   ],
   "source": [
    "# 모델을 로드하고 평가 모드로 전환\n",
    "num_classes = 6  # 총기 클래스 수\n",
    "model = GunshotClassifier(num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('gunshot_classifier.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 데이터 증강 및 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 음원을 예측하는 함수\n",
    "def predict_gunshot(y, model, transform, classes, sr=22050):\n",
    "    mel_spec_db = preprocess_audio(y, sr)\n",
    "    min_val = mel_spec_db.min()\n",
    "    max_val = mel_spec_db.max()\n",
    "    if max_val - min_val != 0:\n",
    "        mel_spec_db = (mel_spec_db - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "    else:\n",
    "        mel_spec_db = np.zeros_like(mel_spec_db)\n",
    "    \n",
    "    mel_spec_db = (mel_spec_db * 255).astype(np.uint8)  # Scale to [0, 255]\n",
    "    image = Image.fromarray(mel_spec_db).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_class = classes[predicted.item()]\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총기 클래스 리스트 (순서는 이전과 동일해야 함)\n",
    "classes = ['ACE', 'AKM', 'AUG', 'M416', 'M762', 'SCAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마이크 입력을 통해 오디오 캡처 및 예측\n",
    "def record_and_predict(duration=1.0, sr=22050):\n",
    "    print(\"Recording...\")\n",
    "    y = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype='float32')\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    y = y.flatten()  # Flatten the array\n",
    "\n",
    "    predicted_class = predict_gunshot(y, model, transform, classes, sr)\n",
    "    print(f'The predicted gunshot class is: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "The predicted gunshot class is: M762\n"
     ]
    }
   ],
   "source": [
    "# 1초 동안 녹음하고 예측\n",
    "record_and_predict(duration=2.0, sr=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
